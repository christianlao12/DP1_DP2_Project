{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.dates import DateFormatter\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "colors = sns.color_palette(\"colorblind\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in SOPHIE Data\n",
    "sophie80df = pd.read_csv(\"Data/SOPHIE_EPT80_1990-2022.csv\", low_memory=False)\n",
    "sophie80df['Date_UTC'] = pd.to_datetime(sophie80df['Date_UTC'])\n",
    "sophie80df = sophie80df[sophie80df['Date_UTC'].between('1996','2022')].reset_index(drop=True)\n",
    "sophie80df['Duration'] = np.append(np.diff(sophie80df['Date_UTC']), np.array([pd.to_timedelta(0,'h')],dtype=np.timedelta64))\n",
    "sophie80df['Delbay'] = pd.to_numeric(sophie80df['Delbay'],errors='coerce')\n",
    "\n",
    "array = np.zeros(len(sophie80df['Date_UTC']),dtype=int)\n",
    "for i in range(4,len(sophie80df['Date_UTC'])-2):\n",
    "    if (sophie80df.iloc[i-4]['Phase'] == 1) and (sophie80df.iloc[i-3]['Phase'] == 2) and (sophie80df.iloc[i-3]['Flag'] == 0) and (sophie80df.iloc[i-2]['Phase'] == 3) and (sophie80df.iloc[i-1]['Phase'] == 1) and (sophie80df.iloc[i]['Phase'] == 2) and (sophie80df.iloc[i+1]['Phase'] == 3) and (sophie80df.iloc[i+2]['Phase'] == 1) :\n",
    "        array[i] = 1\n",
    "        continue\n",
    "    else:\n",
    "        array[i] = 0\n",
    "        continue\n",
    "\n",
    "sophie80df['GERG'] = array\n",
    "\n",
    "array = np.zeros(len(sophie80df['Date_UTC']),dtype=int)\n",
    "for i in range(2,len(sophie80df['Date_UTC'])-1):\n",
    "    if (sophie80df.iloc[i-2]['Phase'] == 2) and (sophie80df.iloc[i-2]['Flag'] == 0) and (sophie80df.iloc[i-1]['Phase'] == 3) and (sophie80df.iloc[i]['Phase'] == 2) and (sophie80df.iloc[i+1]['Phase'] == 3):\n",
    "        array[i] = 1\n",
    "        continue\n",
    "    else:\n",
    "        array[i] = 0\n",
    "        continue\n",
    "\n",
    "sophie80df['ERER'] = array\n",
    "\n",
    "# choosing only sophie onsets\n",
    "sophie80onsetdf = sophie80df.iloc[np.where(sophie80df['Phase']==2)]\n",
    "sophie80onsetdf = sophie80onsetdf.reset_index(drop=True)\n",
    "phaseafter = sophie80df['Date_UTC'].iloc[np.where(sophie80df[:-1]['Phase']==2)[0]+1].reset_index(drop=True) \n",
    "sophie80onsetdf['Waiting Time'] = np.insert(np.array(pd.to_timedelta(np.diff(sophie80onsetdf['Date_UTC']))),0,[pd.to_timedelta(0,'h')])\n",
    "sophie80onsetdf['Time to Next'] = np.append(np.array(pd.to_timedelta(np.diff(sophie80onsetdf['Date_UTC']))),np.array([pd.to_timedelta(0,'h')],dtype=np.timedelta64))\n",
    "sophie80onsetdf['Delbay'] = pd.to_numeric(sophie80onsetdf['Delbay'],errors='coerce')\n",
    "\n",
    "# Loading in SuperMAG Data\n",
    "supermagdatadf = pd.read_csv('Data/SuperMAGData.csv')\n",
    "supermagdatadf['Date_UTC'] = pd.to_datetime(supermagdatadf['Date_UTC'])\n",
    "supermagdatadf[supermagdatadf['Date_UTC'].between('1995','2022')]\n",
    "supermagdatadf['SML'].replace(999999, np.nan, inplace=True)\n",
    "supermagdatadf['SMU'].replace(999999, np.nan, inplace=True)\n",
    "\n",
    "# Loading in OMNI Data\n",
    "omnidf = pd.read_csv('Data/OMNIData.csv')\n",
    "omnidf['Date_UTC'] = pd.to_datetime(omnidf['Date_UTC'])\n",
    "omnidf = omnidf[omnidf['Date_UTC'].between('1995','2022')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the indices of the first and last sophie onsets in a gerg\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "\n",
    "a = x - 1\n",
    "b = np.setdiff1d(a,x)\n",
    "firstgerg = sophie80onsetdf.iloc[np.intersect1d(b,y)]\n",
    "gergnoflag = sophie80onsetdf.iloc[np.concatenate((x,b))]\n",
    "\n",
    "# # Finding the indices of the first and last sophie onsets in a erer\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "a = x - 1\n",
    "b = np.setdiff1d(a,x)\n",
    "firster = sophie80onsetdf.iloc[np.intersect1d(b,y)]\n",
    "erernoflag = sophie80onsetdf.iloc[np.concatenate((x,b))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Periods of Substorm Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Period of Substorm Activity - SML, SW flow speed, Bz\n",
    "sophieslice = sophie80df[sophie80df['Date_UTC'].between('1996-01-02 12:00:00','1996-01-03')]\n",
    "supermagslice = supermagdatadf[supermagdatadf['Date_UTC'].between('1996-01-02 12:00:00','1996-01-03')]\n",
    "onsetslice = sophieslice[sophieslice['Phase']==2]\n",
    "convectionslice = onsetslice[onsetslice['Flag']==1]\n",
    "onsetslice = onsetslice[onsetslice['Flag']==0]\n",
    "gergslice = onsetslice[onsetslice['GERG']==1]\n",
    "ererslice = onsetslice[onsetslice['ERER']==1]\n",
    "recoveryslice = sophieslice[sophieslice['Phase']==3]\n",
    "recoveryslice = recoveryslice[recoveryslice['Flag']==0]\n",
    "growthslice = sophieslice[sophieslice['Phase']==1]\n",
    "omnislice = omnidf[omnidf['Date_UTC'].between('1996-01-02 12:00:00','1996-01-03')]\n",
    "date_form = DateFormatter(\"%Y-%m-%d\\n%H:%M\")\n",
    "\n",
    "fig, (ax,ax1,ax2) = plt.subplots(3,1, figsize=(28,15),sharex=True)\n",
    "    \n",
    "ax.plot(supermagslice['Date_UTC'], supermagslice['SML'], label='SML Index')\n",
    "ax.set_ylabel('SML (nT)')\n",
    "ax.plot([],[],color=colors[2],label='Growth Phase')\n",
    "ax.plot([],[],color=colors[3],label='Isolated Expansion Phase')\n",
    "ax.plot([],[],color=colors[5],label='Compound Expansion Phase')\n",
    "ax.plot([],[],color=colors[4],label='Recovery Phase')\n",
    "ax.plot([],[],color=colors[8],label='Convection Phase')\n",
    "\n",
    "for i in range(len(gergslice)):\n",
    "    ax.axvspan(sophieslice['Date_UTC'][gergslice.index[i]],sophieslice['Date_UTC'][gergslice.index[i]+1], alpha=0.5, color=colors[3])\n",
    "\n",
    "for i in range(len(ererslice)):\n",
    "    ax.axvspan(sophieslice['Date_UTC'][ererslice.index[i]],sophieslice['Date_UTC'][ererslice.index[i]+1], alpha=0.5, color=colors[5], hatch='//')\n",
    "ax.axvspan(sophieslice['Date_UTC'][25],sophieslice['Date_UTC'][25+1], alpha=0.5, color=colors[5],hatch='//')\n",
    "\n",
    "for i in range(len(recoveryslice)):\n",
    "    if i < 2:\n",
    "        ax.axvspan(sophieslice['Date_UTC'][recoveryslice.index[i]],sophieslice['Date_UTC'][recoveryslice.index[i]+1], alpha=0.5, color=colors[4])\n",
    "    else:\n",
    "        ax.axvspan(sophieslice['Date_UTC'][recoveryslice.index[i]],sophieslice['Date_UTC'][recoveryslice.index[i]+1], alpha=0.5, color=colors[4],hatch='//')\n",
    "\n",
    "for i in range(len(convectionslice)):\n",
    "    ax.axvspan(sophieslice['Date_UTC'][convectionslice.index[i]],sophieslice['Date_UTC'][convectionslice.index[i]+2], alpha=0.5, color=colors[8])\n",
    "\n",
    "for i in range(len(growthslice)):\n",
    "    if i != len(growthslice)-1:\n",
    "        ax.axvspan(sophieslice['Date_UTC'][growthslice.index[i]],sophieslice['Date_UTC'][growthslice.index[i]+1], alpha=0.5, color=colors[2])\n",
    "    else:\n",
    "        ax.axvspan(sophieslice['Date_UTC'][growthslice.index[i]],pd.to_datetime('1996-01-03'), alpha=0.5, color=colors[2])\n",
    "\n",
    "ax.axvspan(pd.to_datetime('1996-01-02 12:00:00'),sophieslice['Date_UTC'][sophieslice.index[0]], alpha=0.5, color=colors[2])\n",
    "\n",
    "ax.xaxis.set_major_formatter(date_form)\n",
    "ax.legend(loc='lower left',) \n",
    "ax.set_ylim(top=25)\n",
    "ax.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "ax1.plot(omnislice['Date_UTC'], omnislice['flow_speed'], label='Flow Speed')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.set_ylim(250,750)\n",
    "ax1.set_ylabel('Flow Speed (km/s)')\n",
    "ax1.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "\n",
    "ax2.plot(omnislice['Date_UTC'], omnislice['BZ_GSM'], label='Bz')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.set_ylim(-10,10)\n",
    "ax2.set_ylabel('Bz (nT)')\n",
    "\n",
    "fig.suptitle('SOPHIE Phases, SML Index and OMNI Data')\n",
    "fig.tight_layout(pad=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Period of Substorm Activity - SML, SW flow speed, Bz\n",
    "sophieslice = sophie80df[sophie80df['Date_UTC'].between('1996-01-02 12:00:00','1996-01-03')]\n",
    "supermagslice = supermagdatadf[supermagdatadf['Date_UTC'].between('1996-01-02 12:00:00','1996-01-03')]\n",
    "onsetslice = sophieslice[sophieslice['Phase']==2]\n",
    "convectionslice = onsetslice[onsetslice['Flag']==1]\n",
    "onsetslice = onsetslice[onsetslice['Flag']==0]\n",
    "gergslice = onsetslice[onsetslice['GERG']==1]\n",
    "ererslice = onsetslice[onsetslice['ERER']==1]\n",
    "recoveryslice = sophieslice[sophieslice['Phase']==3]\n",
    "recoveryslice = recoveryslice[recoveryslice['Flag']==0]\n",
    "growthslice = sophieslice[sophieslice['Phase']==1]\n",
    "omnislice = omnidf[omnidf['Date_UTC'].between('1996-01-02 12:00:00','1996-01-03')]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,10),sharex=True)\n",
    "ax.plot(supermagslice['Date_UTC'], supermagslice['SML'], label='SML Index')\n",
    "ax.set_ylabel('SML (nT)')\n",
    "ax.plot([],[],color=colors[2],label='Growth Phase')\n",
    "ax.plot([],[],color=colors[3],label='Isolated Expansion Phase')\n",
    "ax.plot([],[],color=colors[5],label='Compound Expansion Phase')\n",
    "ax.plot([],[],color=colors[4],label='Recovery Phase')\n",
    "ax.plot([],[],color=colors[8],label='Convection Phase')\n",
    "\n",
    "for i in range(len(gergslice)):\n",
    "    ax.axvspan(sophieslice['Date_UTC'][gergslice.index[i]],sophieslice['Date_UTC'][gergslice.index[i]+1], alpha=0.5, color=colors[3])\n",
    "\n",
    "for i in range(len(ererslice)):\n",
    "    ax.axvspan(sophieslice['Date_UTC'][ererslice.index[i]],sophieslice['Date_UTC'][ererslice.index[i]+1], alpha=0.5, color=colors[5], hatch='//')\n",
    "ax.axvspan(sophieslice['Date_UTC'][25],sophieslice['Date_UTC'][25+1], alpha=0.5, color=colors[5],hatch='//')\n",
    "\n",
    "for i in range(len(recoveryslice)):\n",
    "    if i < 2:\n",
    "        ax.axvspan(sophieslice['Date_UTC'][recoveryslice.index[i]],sophieslice['Date_UTC'][recoveryslice.index[i]+1], alpha=0.5, color=colors[4])\n",
    "    else:\n",
    "        ax.axvspan(sophieslice['Date_UTC'][recoveryslice.index[i]],sophieslice['Date_UTC'][recoveryslice.index[i]+1], alpha=0.5, color=colors[4],hatch='//')\n",
    "\n",
    "for i in range(len(convectionslice)):\n",
    "    ax.axvspan(sophieslice['Date_UTC'][convectionslice.index[i]],sophieslice['Date_UTC'][convectionslice.index[i]+2], alpha=0.5, color=colors[8])\n",
    "\n",
    "for i in range(len(growthslice)):\n",
    "    if i != len(growthslice)-1:\n",
    "        ax.axvspan(sophieslice['Date_UTC'][growthslice.index[i]],sophieslice['Date_UTC'][growthslice.index[i]+1], alpha=0.5, color=colors[2])\n",
    "    else:\n",
    "        ax.axvspan(sophieslice['Date_UTC'][growthslice.index[i]],pd.to_datetime('1996-01-03'), alpha=0.5, color=colors[2])\n",
    "\n",
    "ax.axvspan(pd.to_datetime('1996-01-02 12:00:00'),sophieslice['Date_UTC'][sophieslice.index[0]], alpha=0.5, color=colors[2])\n",
    "\n",
    "ax.xaxis.set_major_formatter(date_form)\n",
    "ax.legend(loc='lower left',) \n",
    "ax.set_ylim(top=25)\n",
    "ax.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "# fig.suptitle('SOPHIE Phases', fontsize=16)\n",
    "fig.tight_layout(pad=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions from SOPHIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waitingtime_hist(array):\n",
    "    x, y = np.histogram(array['Waiting Time']/pd.to_timedelta(1,'h'),bins=np.arange(0,12.25,.25))\n",
    "    y = y+.125\n",
    "    y = y[:-1]\n",
    "    d = {'Waiting Time':y,'Density':x/np.sum(x)}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "onsetlists = [sophie80onsetdf, gergnoflag, erernoflag]\n",
    "labels = ['SOPHIE EPT80 All', 'SOPHIE EPT80 Isolated','SOPHIE EPT80 Compound']\n",
    "onsetnumbers = [len(i) for i in onsetlists]\n",
    "means = [np.mean(i['Waiting Time'])/pd.Timedelta(1,'h') for i in onsetlists]\n",
    "stdevs = [np.std(i['Waiting Time'])/pd.Timedelta(1,'h') for i in onsetlists]\n",
    "medians = [np.median(i['Waiting Time'])/pd.Timedelta(1,'h') for i in onsetlists]\n",
    "# labels = [\"{}, {} onsets, mean:  {:.2f}, st. dev: {:.2f}, median: {:.2f}\".format(labels[i],onsetnumbers[i],means[i],stdevs[i],medians[i]) for i in range(len(onsetlists))]\n",
    "labels = [\"{}, {} onsets\".format(labels[i],onsetnumbers[i]) for i in range(len(onsetlists))]\n",
    "\n",
    "lines = ['solid','dashed','dashdot']\n",
    "wts = [waitingtime_hist(i) for i in onsetlists]\n",
    "fig, axes = plt.subplots(figsize=(16,9))\n",
    "\n",
    "for i in range(1,len(onsetlists)):\n",
    "    axes.plot(wts[i]['Waiting Time'],wts[i]['Density'], label=labels[i], ls=lines[i])\n",
    "    \n",
    "axes.xaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
    "axes.set_xlabel('Waiting time (hours)')\n",
    "axes.set_ylabel('Probability Density')\n",
    "axes.grid(True,'both')\n",
    "fig.suptitle('Substorm Waiting Time Distribution')\n",
    "# fig.legend(bbox_to_anchor=(1, .5), loc='center left')\n",
    "axes.legend(loc='upper right')\n",
    "fig.tight_layout(pad=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_hist(array):\n",
    "    x, y = np.histogram(-array['Delbay'],bins=np.arange(0,1000,25))\n",
    "    y = y + 12.5\n",
    "    y = y[:-1]\n",
    "    d = {'Size':y,'Density':x/np.sum(x)}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "onsetlists = [sophie80onsetdf, gergnoflag, erernoflag]\n",
    "labels = ['SOPHIE EPT80 All', 'SOPHIE EPT80 Isolated','SOPHIE EPT80 Compound']\n",
    "onsetnumbers = [len(i) for i in onsetlists]\n",
    "means = [np.nanmean(-i['Delbay']) for i in onsetlists]\n",
    "stdevs = [np.nanstd(-i['Delbay']) for i in onsetlists]\n",
    "medians = [np.nanmedian(-i['Delbay']) for i in onsetlists]\n",
    "# labels = [\"{}, {} onsets, mean:  {:.2f}, st. dev: {:.2f}, median: {:.2f}\".format(labels[i],onsetnumbers[i],means[i],stdevs[i],medians[i]) for i in range(len(onsetlists))]\n",
    "labels = [\"{}, {} onsets\".format(labels[i],onsetnumbers[i]) for i in range(len(onsetlists))]\n",
    "\n",
    "lines = ['solid','dashed','dashdot']\n",
    "wts = [size_hist(i) for i in onsetlists]\n",
    "fig, axes = plt.subplots(figsize=(14,9))\n",
    "\n",
    "for i in range(1,len(onsetlists)):\n",
    "    axes.plot(wts[i]['Size'],wts[i]['Density'], label=labels[i],ls=lines[i])\n",
    "    \n",
    "axes.set_xlabel('Substorm Size (nT)')\n",
    "axes.set_ylabel('Probability Density')\n",
    "axes.grid(True,'both')\n",
    "fig.suptitle('Substorm Size Distribution')\n",
    "# fig.legend(bbox_to_anchor=(1, .5), loc='center left')\n",
    "axes.legend(loc='upper right')\n",
    "fig.tight_layout(pad=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_hist(array):\n",
    "    x, y = np.histogram(array['Duration']/pd.to_timedelta(1,'m'),bins=np.arange(0,120,1))\n",
    "    y = y+.5\n",
    "    y = y[:-1]\n",
    "    d = {'Duration':y,'Density':x/np.sum(x)}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "onsetlists = [sophie80onsetdf, gergnoflag, erernoflag]\n",
    "labels = ['SOPHIE EPT80 All', 'SOPHIE EPT80 Isolated','SOPHIE EPT80 Compound']\n",
    "onsetnumbers = [len(i) for i in onsetlists]\n",
    "means = [np.mean(i['Duration'])/pd.Timedelta(1,'m') for i in onsetlists]\n",
    "stdevs = [np.std(i['Duration'])/pd.Timedelta(1,'m') for i in onsetlists]\n",
    "medians = [np.median(i['Duration'])/pd.Timedelta(1,'m') for i in onsetlists]\n",
    "# labels = [\"{}, {} onsets, mean:  {:.2f}, st. dev: {:.2f}, median: {:.2f}\".format(labels[i],onsetnumbers[i],means[i],stdevs[i],medians[i]) for i in range(len(onsetlists))]\n",
    "labels = [\"{}, {} onsets\".format(labels[i],onsetnumbers[i]) for i in range(len(onsetlists))]\n",
    "\n",
    "lines = ['solid','dashed','dashdot']\n",
    "wts = [duration_hist(i) for i in onsetlists]\n",
    "fig, axes = plt.subplots(figsize=(16,9))\n",
    "\n",
    "for i in range(1,len(onsetlists)):\n",
    "    axes.plot(wts[i]['Duration'],wts[i]['Density'], label=labels[i], ls=lines[i])\n",
    "    \n",
    "axes.set_xlabel('Expansion Duration (mins)')\n",
    "axes.set_ylabel('Probability Density')\n",
    "axes.grid(True,'both')\n",
    "fig.suptitle('Substorm Expansion Duration Distribution')\n",
    "# fig.legend(bbox_to_anchor=(1, .5), loc='center left')\n",
    "axes.legend(loc='upper right')\n",
    "fig.tight_layout(pad=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlat_hist(array):\n",
    "    x, y = np.histogram(array['MLat'],bins=np.arange(40,85,1))\n",
    "    y = y + .5\n",
    "    y = y[:-1]\n",
    "    d = {'MLat':y,'Density':x/np.sum(x)}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "onsetlists = [sophie80onsetdf, gergnoflag, erernoflag]\n",
    "labels = ['SOPHIE EPT80 All', 'SOPHIE EPT80 Isolated','SOPHIE EPT80 Compound']\n",
    "onsetnumbers = [len(i) for i in onsetlists]\n",
    "means = [np.mean(i['MLat']) for i in onsetlists]\n",
    "stdevs = [np.std(i['MLat']) for i in onsetlists]\n",
    "medians = [np.median(i['MLat']) for i in onsetlists]\n",
    "# labels = [\"{}, {} onsets, mean:  {:.2f}, st. dev: {:.2f}, median: {:.2f}\".format(labels[i],onsetnumbers[i],means[i],stdevs[i],medians[i]) for i in range(len(onsetlists))]\n",
    "labels = [\"{}, {} onsets\".format(labels[i],onsetnumbers[i]) for i in range(len(onsetlists))]\n",
    "\n",
    "lines = ['solid','dashed','dashdot']\n",
    "wts = [mlat_hist(i) for i in onsetlists]\n",
    "fig, axes = plt.subplots(figsize=(16,9))\n",
    "\n",
    "for i in range(1,len(onsetlists)):\n",
    "    axes.plot(wts[i]['MLat'],wts[i]['Density'], label=labels[i],ls=lines[i])\n",
    "    \n",
    "\n",
    "axes.set_xlim(40,85)\n",
    "axes.set_xlabel('Substorm Onset Location (MLat)')\n",
    "axes.set_ylabel('Probability Density')\n",
    "axes.grid(True,'both')\n",
    "fig.suptitle('Substorm MLat distribution')\n",
    "# fig.legend(bbox_to_anchor=(1, .5), loc='center left')\n",
    "axes.legend(loc='upper left')\n",
    "fig.tight_layout(pad=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlt_hist(array):\n",
    "    x, y = np.histogram(array['MLT'],bins=np.arange(0,25))\n",
    "    y = y\n",
    "    y = y[:-1]\n",
    "    d = {'MLT':y,'Density':x/np.sum(x)}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "onsetlists = [sophie80onsetdf, gergnoflag, erernoflag]\n",
    "labels = ['SOPHIE EPT80 All', 'SOPHIE EPT80 Isolated','SOPHIE EPT80 Compound']\n",
    "onsetnumbers = [len(i) for i in onsetlists]\n",
    "means = [np.mean(i['MLT']) for i in onsetlists]\n",
    "stdevs = [np.std(i['MLT']) for i in onsetlists]\n",
    "medians = [np.median(i['MLT']) for i in onsetlists]\n",
    "# labels = [\"{}, {} onsets\".format(labels[i],onsetnumbers[i]) for i in range(len(onsetlists))]\n",
    "labels = [\"{}, {} onsets\".format(labels[i],onsetnumbers[i]) for i in range(len(onsetlists))]\n",
    "\n",
    "lines = ['solid','dashed','dashdot']\n",
    "wts = [mlt_hist(i) for i in onsetlists]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(16,9))\n",
    "idx = np.array([np.arange(12,24),np.arange(0,12)]).flatten()\n",
    "xx = [wts[i]['MLT'][idx].to_numpy().astype(str) for i in range(len(onsetlists))]\n",
    "yy = [wts[i]['Density'][idx].to_numpy() for i in range(len(onsetlists))]\n",
    "\n",
    "for i in range(1,len(onsetlists)):\n",
    "    axes.plot(xx[i],yy[i], label=labels[i],ls=lines[i])\n",
    "\n",
    "    \n",
    "axes.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "axes.set_xlabel('Substorm Onset Location MLT')\n",
    "axes.set_ylabel('Probability Density')\n",
    "axes.grid(True,'both')\n",
    "fig.suptitle('Substorm MLT distribution')\n",
    "# fig.legend(bbox_to_anchor=(1, .5), loc='center left')\n",
    "axes.legend(loc='upper left')\n",
    "fig.tight_layout(pad=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains of Substorm Activity -  Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting chain lengths\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[np.intersect1d(x,y)] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "# label = 'No. of expansion onsets: {}, Mean: {:.2f}, St. Dev: {:.2f}, Median: {:.2f}, Max: {}'.format(len(gergnoflag)+len(firstgerg),np.mean(co), np.std(co), np.median(co), np.max(co))\n",
    "label = 'No. of expansion onsets: {}, Longest Chain: {}'.format(len(gergnoflag), np.max(co))\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1),density=True)\n",
    "x = x[:-1]\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(2,1, figsize=(20,14),sharex=True, sharey=True)\n",
    "ax.bar(x,y,label=label)\n",
    "ax.set_xlabel('Length of repeating pattern')\n",
    "ax.set_ylabel('Probability Density')\n",
    "ax.set_title(\"Isolated event repeating statistics\")\n",
    "# ax.legend(bbox_to_anchor=(1, .5), loc='center left')\n",
    "ax.legend(loc='upper right')\n",
    "ax.xaxis.set_tick_params(labelbottom=True)\n",
    "ax.set_xlim(right=20)\n",
    "\n",
    "\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[np.intersect1d(x,y)] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "# label = 'No. of expansion onsets: {}, Mean: {:.2f}, St. Dev: {:.2f}, Median: {:.2f}, Max: {}'.format(len(erernoflag)+len(firster),np.mean(co), np.std(co), np.median(co), np.max(co))\n",
    "label = 'No. of expansion onsets: {}, Longest Chain: {}'.format(len(erernoflag), np.max(co))\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1),density=True)\n",
    "x = x[:-1]\n",
    "\n",
    "ax1.bar(x,y,label=label)\n",
    "ax1.set_xlabel('Length of repeating pattern')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.set_title(\"Compound event repeating statistics\")\n",
    "# ax1.legend(bbox_to_anchor=(1, .5), loc='center left')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.xaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "fig.tight_layout(pad=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting chain lengths\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[np.intersect1d(x,y)] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "# label = 'No. of expansion onsets: {}, Mean: {:.2f}, St. Dev: {:.2f}, Median: {:.2f}, Max: {}'.format(len(gergnoflag)+len(firstgerg),np.mean(co), np.std(co), np.median(co), np.max(co))\n",
    "label = 'No. of expansion onsets: {}, Longest Chain: {}'.format(len(gergnoflag), np.max(co))\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1),density=False)\n",
    "x = x[:-1]\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(2,1, figsize=(20,14),sharex=True, sharey=True)\n",
    "ax.bar(x,y,label=label)\n",
    "ax.set_xlabel('Length of repeating pattern')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_title(\"Isolated event repeating statistics\")\n",
    "ax.legend(loc='upper right')\n",
    "ax.xaxis.set_tick_params(labelbottom=True)\n",
    "ax.set_xlim(right=20)\n",
    "\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[np.intersect1d(x,y)] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "# label = 'No. of expansion onsets: {}, Mean: {:.2f}, St. Dev: {:.2f}, Median: {:.2f}, Max: {}'.format(len(erernoflag)+len(firster),np.mean(co), np.std(co), np.median(co), np.max(co))\n",
    "label = 'No. of expansion onsets: {}, Longest Chain: {}'.format(len(erernoflag), np.max(co))\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1),density=False)\n",
    "x = x[:-1]\n",
    "\n",
    "ax1.bar(x,y,label=label)\n",
    "ax1.set_xlabel('Length of repeating pattern')\n",
    "ax1.set_ylabel('Counts')\n",
    "ax1.set_title(\"Compound event repeating statistics\")\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.xaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "fig.tight_layout(pad=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of gerg chain lengths\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x = x[:-1]\n",
    "yerror = [np.sqrt(i) for i in y]\n",
    "print(list(zip(x,y)))\n",
    "if np.where(y==0)[0].size > 0:\n",
    "    yanalysis = y[:np.where(y==0)[0][0]]\n",
    "else:\n",
    "    yanalysis = y\n",
    "\n",
    "\n",
    "yerror = yerror/np.sum(y)\n",
    "yerror = 3*yerror\n",
    "y = y/np.sum(y)\n",
    "yanalysis = yanalysis/sum(yanalysis)\n",
    "\n",
    "ratio = np.array([yanalysis[i]/yanalysis[i-1] for i in range(1,len(yanalysis))])\n",
    "ratioerror = np.array([np.sqrt((yerror[i]/yanalysis[i])**2 + (yerror[i-1]/yanalysis[i-1])**2) for i in range(1,len(yanalysis))])\n",
    "ratioerror = ratioerror*ratio\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(2,1,sharex=True,figsize=(15,15))\n",
    "\n",
    "ax.bar(x,y,yerr=yerror,label='Number of onsets: {}, max chain length: {}'.format(len(gergnoflag),np.max(co)))\n",
    "ax.legend(loc='center right')\n",
    "ax.set_ylabel('Probability Density')\n",
    "ax.set_xlim(right=16)\n",
    "ax.set_ylim(0, 0.7)\n",
    "ax.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "ax1.scatter(x[:len(ratio)]+1, ratio[:len(ratio)])\n",
    "ax1.errorbar(x[:len(ratio)]+1, ratio[:len(ratio)], yerr=ratioerror, fmt='none', ecolor='r', elinewidth=1, capsize=2)\n",
    "ax1.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax1.set_xlabel(\"Length of repeat\")\n",
    "ax1.set_ylabel('Transition Probability')\n",
    "ax1.set_title(\"Probability of Transition to Next Length\")\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.fill_between(x[:len(ratio)]+1, ratio[0]-ratioerror[0], ratio[0]+ratioerror[0], alpha=0.2)\n",
    "ax1.hlines(0.5,0,16,linestyles='dashed',colors='k')\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=1)\n",
    "fig.suptitle('Isolated event repeating statistics',y=1.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of erer chain lengths\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x = x[:-1]\n",
    "print(list(zip(x,y)))\n",
    "yerror = [np.sqrt(i) for i in y]\n",
    "if np.where(y==0)[0].size > 0:\n",
    "    yanalysis = y[:np.where(y==0)[0][0]]\n",
    "else:\n",
    "    yanalysis = y\n",
    "\n",
    "yerror = yerror/np.sum(y)\n",
    "yerror = 3*yerror\n",
    "y = y/np.sum(y)\n",
    "yanalysis = yanalysis/sum(yanalysis)\n",
    "\n",
    "\n",
    "ratio = np.array([yanalysis[i]/yanalysis[i-1] for i in range(1,len(yanalysis))])\n",
    "ratioerror = np.array([np.sqrt((yerror[i]/yanalysis[i])**2 + (yerror[i-1]/yanalysis[i-1])**2) for i in range(1,len(yanalysis))])\n",
    "ratioerror = ratioerror*ratio\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(2,1,sharex=True,figsize=(15,15))\n",
    "\n",
    "ax.bar(x,y,yerr=yerror,label='Number of onsets: {}, max chain length: {}'.format(len(erernoflag),np.max(co)))\n",
    "ax.legend(loc='center right')\n",
    "ax.set_ylabel('Probability Density')\n",
    "ax.set_xlim(right=16)\n",
    "ax.set_ylim(0, 0.7)\n",
    "ax.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "ax1.scatter(x[:len(ratio)]+1, ratio[:len(ratio)])\n",
    "ax1.errorbar(x[:len(ratio)]+1, ratio[:len(ratio)], yerr=ratioerror, fmt='none', ecolor='r', elinewidth=1, capsize=2)\n",
    "ax1.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax1.set_xlabel(\"Length of repeat\")\n",
    "ax1.set_ylabel('Transition Probability')\n",
    "ax1.set_title(\"Probability of Transition to Next Length\")\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.fill_between(x[:len(ratio)]+1, ratio[0]-ratioerror[0], ratio[0]+ratioerror[0], alpha=0.2)\n",
    "ax1.hlines(0.5,0,16,linestyles='dashed',colors='k')\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=1)\n",
    "fig.suptitle(\"Compound event repeating statistics\", y=1.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting SML and Solar Wind Conditions of Chain lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting various parameters of specific gerg chain lengths\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "\n",
    "len_repeat = 15\n",
    "\n",
    "index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "\n",
    "for i in index_repeat:\n",
    "    start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[i])[0][0]    \n",
    "    stop = start + (len_repeat - 1)\n",
    "    sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "    sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "    onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "    tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "    tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "    supermagslice = supermagdatadf[supermagdatadf['Date_UTC'].between(tstart,tend)]\n",
    "    omnislice = omnidf[omnidf['Date_UTC'].between(tstart,tend)]\n",
    "\n",
    "    fig, (ax, ax1, ax2, ax3) = plt.subplots(4,1,figsize=(14,8),sharex=True)\n",
    "    \n",
    "    ax.plot(supermagslice['Date_UTC'], supermagslice['SML'], label='SML')\n",
    "    ax.set_ylabel('SML (nT)')\n",
    "    date_form = DateFormatter(\"%Y-%m-%d\\n%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_form)\n",
    "    ax.legend(loc='upper right') \n",
    "    ax.set_ylim(top=25)\n",
    "    ax.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    for j in range(len(onsetslice)):\n",
    "        ax.axvspan(onsetslice['Date_UTC'][onsetslice.index[j]], onsetslice['Date_UTC'][onsetslice.index[j]]+onsetslice['Duration'][onsetslice.index[j]], alpha=0.5, color='red')\n",
    "    \n",
    "    ax1.plot(omnislice['Date_UTC'],omnislice['F'],label='BT')\n",
    "    ax1.plot(omnislice['Date_UTC'],omnislice['BX_GSE'],label='Bx')\n",
    "    ax1.plot(omnislice['Date_UTC'],omnislice['BZ_GSM'],label='By')\n",
    "    ax1.plot(omnislice['Date_UTC'],omnislice['BY_GSM'],label='Bz')\n",
    "    ax1.set_ylabel('IMF (nT)')\n",
    "    ax1.xaxis.set_major_formatter(date_form)\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_ylim(-20,20)\n",
    "    ax1.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "\n",
    "    ax2.plot(omnislice['Date_UTC'],omnislice['flow_speed'],label='Flow speed')\n",
    "    ax2.plot(omnislice['Date_UTC'],omnislice['Vx'],label='Vx')\n",
    "    ax2.plot(omnislice['Date_UTC'],omnislice['Vy'],label='Vy')\n",
    "    ax2.plot(omnislice['Date_UTC'],omnislice['Vz'],label='Vz')\n",
    "    ax2.set_ylabel('Solar wind velocities (km/s)')\n",
    "    ax2.xaxis.set_major_formatter(date_form)\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_ylim(-1000,1000)\n",
    "    ax2.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    ax3.plot(omnislice['Date_UTC'],omnislice['proton_density'],label='proton density')\n",
    "    ax3.set_ylabel('Proton density (cm^-3)')\n",
    "    ax3.xaxis.set_major_formatter(date_form)\n",
    "    ax3.legend(loc='upper right')\n",
    "    ax3.set_ylim(0,50)\n",
    "    fig.suptitle('Isolated Substorm repeat of length {}'.format(len_repeat),y=1)\n",
    "\n",
    "    plt.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting various parameters for specific erer chain lengths\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "\n",
    "len_repeat = 15\n",
    "\n",
    "index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "\n",
    "for i in index_repeat:\n",
    "    start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[i])[0][0]    \n",
    "    stop = start + (len_repeat - 1)\n",
    "    sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "    sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "    onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "    tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "    tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "    supermagslice = supermagdatadf[supermagdatadf['Date_UTC'].between(tstart,tend)]\n",
    "    omnislice = omnidf[omnidf['Date_UTC'].between(tstart,tend)]\n",
    "\n",
    "    fig, (ax, ax1, ax2, ax3) = plt.subplots(4,1,figsize=(14,8),sharex=True)\n",
    "    \n",
    "    ax.plot(supermagslice['Date_UTC'], supermagslice['SML'], label='SML')\n",
    "    ax.set_ylabel('SML (nT)')\n",
    "    date_form = DateFormatter(\"%Y-%m-%d\\n%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_form)\n",
    "    ax.legend(loc='upper right') \n",
    "    ax.set_ylim(top=25)\n",
    "    ax.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    for j in range(len(onsetslice)):\n",
    "        ax.axvspan(onsetslice['Date_UTC'][onsetslice.index[j]], onsetslice['Date_UTC'][onsetslice.index[j]]+onsetslice['Duration'][onsetslice.index[j]], alpha=0.5, color='red')\n",
    "    \n",
    "    ax1.plot(omnislice['Date_UTC'],omnislice['F'],label='BT')\n",
    "    ax1.plot(omnislice['Date_UTC'],omnislice['BX_GSE'],label='Bx')\n",
    "    ax1.plot(omnislice['Date_UTC'],omnislice['BZ_GSM'],label='By')\n",
    "    ax1.plot(omnislice['Date_UTC'],omnislice['BY_GSM'],label='Bz')\n",
    "    ax1.set_ylabel('IMF (nT)')\n",
    "    ax1.xaxis.set_major_formatter(date_form)\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_ylim(-25,25)\n",
    "    ax1.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    ax2.plot(omnislice['Date_UTC'],omnislice['flow_speed'],label='Flow speed')\n",
    "    ax2.plot(omnislice['Date_UTC'],omnislice['Vx'],label='Vx')\n",
    "    ax2.plot(omnislice['Date_UTC'],omnislice['Vy'],label='Vy')\n",
    "    ax2.plot(omnislice['Date_UTC'],omnislice['Vz'],label='Vz')\n",
    "    ax2.set_ylabel('Solar wind velocities (km/s)')\n",
    "    ax2.xaxis.set_major_formatter(date_form)\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_ylim(-1000,1000)\n",
    "    ax2.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    ax3.plot(omnislice['Date_UTC'],omnislice['proton_density'],label='proton density')\n",
    "    ax3.set_ylabel('Proton density (cm^-3)')\n",
    "    ax3.xaxis.set_major_formatter(date_form)\n",
    "    ax3.legend(loc='upper right')\n",
    "    ax3.set_ylim(0,50)\n",
    "    \n",
    "    fig.suptitle('Compound Substorm repeat of length {}'.format(len_repeat),y=1)\n",
    "\n",
    "    plt.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Speed vs Chain Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolated chain lengths vs flow speed\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(200,1001,25)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['flow_speed'].values)\n",
    "            \n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True), vmax=0.3)\n",
    "ax.set_xlabel(\"Isolated Chain Length\")\n",
    "ax.set_ylabel(\"Solar Wind Speed (km/s)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='1 Standard Deviation',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Isolated Chain Length vs Solar Wind Speed')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound chain lengths vs flow speed\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(200,1001,25)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['flow_speed'].values)\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.3)\n",
    "ax.set_xlabel(\"Compound Chain Length\")\n",
    "ax.set_ylabel(\"Solar Wind Speed (km/s)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='1 Standard Deviation',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Compound Chain Length vs Solar Wind Speed')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMF Magnitude vs Chain Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolated chain lengths vs IMF Magnitude\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(0,20.5,0.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['F'].values)\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.25)\n",
    "ax.set_xlabel(\"Isolated Chain Length\")\n",
    "ax.set_ylabel(\"IMF Magnitude (nT)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='1 Standard Deviation',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Isolated Chain Length vs IMF Magnitude')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound chain lengths vs IMF Magnitude\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(0,20.5,.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['F'].values)\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.25)\n",
    "ax.set_xlabel(\"Compound Chain Length\")\n",
    "ax.set_ylabel(\"IMF Magnitude (nT)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='St Dev',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Compound Chain Length vs IMF Magnitude')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMF Bz vs Chain Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolated chain lengths vs Bz\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(-15,15.5,0.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['BZ_GSM'].values)\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.1)\n",
    "ax.set_xlabel(\"Isolated Chain Length\")\n",
    "ax.set_ylabel(\"Bz (nT)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(2.5))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='1 Standard Deviation',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Isolated Chain Length vs Bz')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound chain lengths vs Bz \n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(-15,15.5,0.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "\n",
    "        len_repeat = x[i]\n",
    "\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['BZ_GSM'].values)\n",
    "            # print('Yay! {} done!'.format(np.where(index_repeat==j)[0][0]))\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.1)\n",
    "ax.set_xlabel(\"Compound Chain Length\")\n",
    "ax.set_ylabel(\"Bz (nT)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(2.5))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='1 Standard Deviation',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Compound Chain Length vs Bz')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMF Bx vs Chain Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolated chain lengths vs Bx\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(-10,10.5,0.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['BX_GSE'].values)\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.1)\n",
    "ax.set_xlabel(\"Isolated Chain Length\")\n",
    "ax.set_ylabel(\"Bx (nT)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='1 Standard Deviation',ls='None',marker='')\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Isolated Chain Length vs Bx')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound chain lengths vs Bx\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(-10,10.5,0.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['BX_GSE'].values)\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.1)\n",
    "ax.set_xlabel(\"Compound Chain Length\")\n",
    "ax.set_ylabel(\"Bx (nT)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='St Dev',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Compound Chain Length vs Bx')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMF By vs Chain Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolated chain lengths vs By\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(-10,10.5,0.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['BY_GSM'].values)\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.1)\n",
    "ax.set_xlabel(\"Isolated Chain Length\")\n",
    "ax.set_ylabel(\"By (nT)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='1 Standard Deviation',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Isolated Chain Length vs By')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound chain lengths vs By\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(-10,10.5,0.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['BY_GSM'].values)\n",
    "            \n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.1)\n",
    "ax.set_xlabel(\"Compound Chain Length\")\n",
    "ax.set_ylabel(\"By (nT)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='St Dev',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Compound Chain Length vs By')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proton Density vs Chain Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolated chain lengths vs Proton Density\n",
    "x = np.where(sophie80onsetdf['GERG']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(0,25.5,0.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "        len_repeat = x[i]\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['proton_density'].values)\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.1)\n",
    "ax.set_xlabel(\"Isolated Chain Length\")\n",
    "ax.set_ylabel(\"Proton Density (n/cc)\")\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='1 Standard Deviation',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Isolated Chain Length vs Proton Density')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound chain lengths vs Proton Density\n",
    "x = np.where(sophie80onsetdf['ERER']==1)[0]\n",
    "y = np.where(sophie80onsetdf['Flag']==0)[0]\n",
    "indices_onsets =np.intersect1d(x,y)\n",
    "s = np.zeros(len(sophie80onsetdf))\n",
    "s[indices_onsets] = True\n",
    "s = pd.Series(s.astype(bool))\n",
    "co = (~s).cumsum()[s].value_counts().to_list()\n",
    "co = [i+1 for i in co]\n",
    "y, x = np.histogram(co, bins=np.arange(2,np.max(co)+2,1))\n",
    "x_edges = x - 0.5\n",
    "x = x[:-1]\n",
    "y_edges = np.arange(0,25.5,0.5)\n",
    "\n",
    "valuehist = []\n",
    "valuemean = []\n",
    "valuestd = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if y[i] == 0:\n",
    "        valuehist.append(np.zeros_like(y_edges[:-1]))\n",
    "        valuemean.append(np.nan)\n",
    "        valuestd.append(np.nan)\n",
    "\n",
    "    else:\n",
    "\n",
    "        len_repeat = x[i]\n",
    "\n",
    "        index_repeat = np.where(((~s).cumsum()[s].value_counts()+1)==len_repeat)[0]\n",
    "\n",
    "        valueloop = []\n",
    "\n",
    "        for j in index_repeat:\n",
    "            start = np.where((~s).cumsum()[s]==(~s).cumsum()[s].value_counts().index[j])[0][0]\n",
    "            stop = start + (len_repeat - 1)\n",
    "            sophieindicesstart = (~s).cumsum()[s][start:stop].index[0]\n",
    "            sophieindicesstop = (~s).cumsum()[s][start:stop].index[-1] + 1\n",
    "            onsetslice = sophie80onsetdf.iloc[sophieindicesstart-1:sophieindicesstop]\n",
    "            tstart = onsetslice['Date_UTC'][onsetslice.index[0]]\n",
    "            tend = onsetslice['Date_UTC'][onsetslice.index[-1]]+onsetslice['Duration'][onsetslice.index[-1]]\n",
    "\n",
    "            valueloop.append(omnidf[omnidf['Date_UTC'].between(tstart,tend)]['proton_density'].values)\n",
    "            # print('Yay! {} done!'.format(np.where(index_repeat==j)[0][0]))\n",
    "\n",
    "        valueloop = np.concatenate(valueloop).ravel()\n",
    "        valueloophist = np.histogram(valueloop,bins=y_edges)[0]\n",
    "        valueloophist = valueloophist/np.sum(valueloophist)\n",
    "        valueloopmean = np.nanmean(valueloop)\n",
    "        valueloopstd = np.nanstd(valueloop)\n",
    "\n",
    "        valuehist.append(valueloophist)\n",
    "        valuemean.append(valueloopmean)\n",
    "        valuestd.append(valueloopstd)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "values = np.array(valuehist)\n",
    "\n",
    "X,Y = np.meshgrid(x_edges,y_edges)\n",
    "plot = ax.pcolormesh(X, Y, values.T,cmap=sns.color_palette(\"rocket\",as_cmap=True),vmax=0.1)\n",
    "ax.set_xlabel(\"Compound Chain Length\")\n",
    "ax.set_ylabel(\"Proton Density (n/cc)\")\n",
    "ax.set_ylim(0,25)\n",
    "plt.colorbar(plot, ax=ax)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.scatter(x,valuemean,label='Mean',marker='x')\n",
    "ax.errorbar(x,valuemean,yerr=valuestd,label='St Dev',ls='None',marker='')\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Compound Chain Length vs Proton Density')\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7e59fed02121d01c1a84739d8806ac49fa4a99ee8d672a1e482ab4a94ed6822"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
